{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53d26b9-7505-433b-9361-e497c1ddccac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyzing Performance\n",
    "\n",
    "## Using Linux built-in performance measurement tools\n",
    "\n",
    "One of the most prolific tools (as you may have read in the textbook) is the `time` ([man page](https://man7.org/linux/man-pages/man1/time.1.html)) tool built into Linux and BSD (amongst other operating systems), usually located at `/usr/bin/time`.  To run `/usr/bin/time`, simply just add it on the same line where you call `python` or your compiled program at the beginning of the line in your `%%qsub` cells.  \n",
    "\n",
    "Note that it will print, by default: the CPU usage by the program code (user), the CPU usage by the system (system), the Wall time (elapsed), the percentage of CPU used, and different information about the RAM usage.\n",
    "\n",
    "You can customize it yourself by feeding the `--format=\"...\"` parameters, by replacing the ellipsis with a printf-style format string.\n",
    "\n",
    "For instance, if we want to time the program `sleep 5`, with the format string `\"real %e system %S cpu %P avg_ram_kb %K\"`, our line would look like:\n",
    "\n",
    "`/usr/bin/time --format=\"real %e system %S cpu %P avg_ram_kb %K\" sleep 5`\n",
    "\n",
    "**NOTE**: The output from this tool will appear in the error buffer instead (`STDIN.eNNNNNN`), so make sure you look for through both the standard output and the standard error files.  Make sure to look through the `STDIN.oNNNNN` file too, so that you have the job number and can know which run was with which parameters.\n",
    "\n",
    "Try using this tool on your code in the following cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e090e1-a0c0-40d2-9a70-95fde52ddf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ParallelCode.py\n",
    "\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import random\n",
    "import timeit \n",
    "import time\n",
    "from multiprocessing import Array\n",
    "\n",
    "# definition of monte carlo method to find pi\n",
    "def monte_carlo_definition():\n",
    "    # get random x and y points\n",
    "    x = random.uniform(-1.0,1.0)\n",
    "    y = random.uniform(-1.0,1.0)\n",
    "    \n",
    "    # determine if the points are in the circle of pi\n",
    "    return np.square(x) + np.square(y) <= 1\n",
    "\n",
    "# mini parallelized method\n",
    "def parallel_monte_carlo_sub_act(sizeOfSubArray, completeSum, i):\n",
    "    # get the smaller sized array (sizeofArray) of random points \n",
    "    completeSum[i] = sum(monte_carlo_definition() for j in range(sizeOfSubArray))\n",
    "\n",
    "# parallelized method main call\n",
    "def monte_carlo_parallel(numberOfSampleTrials: int = 1000000, numberOfProcesses: int = 6):\n",
    "    sizeOfSubArray = int(numberOfSampleTrials/numberOfProcesses) # size of the mini array passed to the processes in parallel\n",
    "    completeSum = Array('i', [0]*numberOfProcesses, lock=False) # instantiate array to keep track of circle points\n",
    "    processes = [] # array that will hold the processes executed\n",
    "    \n",
    "    # loop through the amount of processes in the program (4 in this case)\n",
    "    for i in range(numberOfProcesses):\n",
    "        process = multiprocessing.Process(target=parallel_monte_carlo_sub_act, args=(sizeOfSubArray, completeSum, i))\n",
    "        \n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "    \n",
    "    # important to make sure process has enough time to execute\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    pi = 4.0 * (sum(completeSum))/numberOfSampleTrials\n",
    "    print(\"Parallel approximation of pi with size \"+str(numberOfSampleTrials)+\" and \"+str(numberOfProcesses)+\" workers: \", end=' ')\n",
    "    print(pi)\n",
    "    return pi\n",
    "    \n",
    "def main() -> None:\n",
    "    start_time = time.time()\n",
    "    monte_carlo_parallel(100000000, 2)\n",
    "    print(\"--- %s seconds to complete ---\" % (time.time() - start_time))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #print(\"Replace this with proper timeit calls\")\n",
    "    timer_main = timeit.Timer(main)\n",
    "    timer_main.repeat(repeat=1, number=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc0905-512b-4f42-b01e-4b7d06f617a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfxmagic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670c142-97e2-4336-b9b6-12532014c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%qsub \n",
    "cd $PBS_O_WORKDIR\n",
    "/usr/bin/time python ParallelCode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc43b9-2337-44e1-b195-b67de1e97dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f2c95-d0b4-4ac9-96ed-bb6221df2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "!qdel 1906339"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ad6c1-5c94-41d4-9cc8-1772a5a332b7",
   "metadata": {},
   "source": [
    "## Collecting run data\n",
    "\n",
    "To make sure that we have adequate data, make sure to submit at least 10 different variations of your code, such as the following example variations (based on the Monte Carlo example):\n",
    "\n",
    "1. Run with draw number size 10000000 and 2 workers\n",
    "1. Run with draw number size 10000000 and 4 workers\n",
    "1. Run with draw number size 10000000 and 6 workers\n",
    "1. Run with draw number size 10000000 and 8 workers\n",
    "1. Run with draw number size 10000000 and 10 workers\n",
    "1. Run with draw number size 10000000 and 12 workers\n",
    "1. Run with draw number size 10000000 and 14 workers\n",
    "1. Run with draw number size 10000000 and 16 workers\n",
    "1. Run with draw number size 100000000 and 8 workers\n",
    "1. Run with draw number size 100000000 and 16 workers\n",
    "1. Run with draw number size 1000000000 and 8 workers\n",
    "1. Run with draw number size 1000000000 and 16 workers\n",
    "1. Run with draw number size 10000000000 and 8 workers\n",
    "1. Run with draw number size 10000000000 and 16 workers\n",
    "\n",
    "Now, go ahead and use the two cells below to run your job for different variations (you can either programmatically run the variations or just manually run each variation here and just note the data down)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1270352-f5ba-48dd-816f-2d1fce8a5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times to complete for each (seconds) using 'time' module\n",
    "# using method monte_carlo_parallel(numberOfSamples, numberOfWorkers)\n",
    "\n",
    "#monte_carlo_parallel(10000000, 2)\n",
    "# 26.37137222290039 seconds to complete\n",
    "\n",
    "#monte_carlo_parallel(10000000, 4)\n",
    "# 12.796449184417725 seconds to complete\n",
    "\n",
    "#monte_carlo_parallel(10000000, 6)\n",
    "# 8.501582622528076 seconds to \n",
    "\n",
    "#monte_carlo_parallel(10000000, 8)\n",
    "# 6.437229156494141 seconds to complete\n",
    "\n",
    "#monte_carlo_parallel(10000000, 10)\n",
    "# 5.096891403198242 seconds to complete\n",
    "\n",
    "#monte_carlo_parallel(10000000, 12)\n",
    "# 4.514995336532593 seconds to complete\n",
    "\n",
    "#monte_carlo_parallel(10000000, 14)\n",
    "# 5.060871839523315 seconds to complete\n",
    "\n",
    "#monte_carlo_parallel(10000000, 16)\n",
    "# 4.5333778858184814 seconds to complete\n",
    "\n",
    "#monte_carlo_parallel(10000000, 18)\n",
    "# 4.334452152252197 seconds to complete\n",
    "\n",
    "#monte_carlo_parallel(10000000, 20)\n",
    "# 4.195279359817505 seconds to complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf334b8-79a1-4f79-8060-b1dbbee340c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97fea7a7-3a31-40c4-8350-c64820b4a9e3",
   "metadata": {},
   "source": [
    "We can also submit to different types of machines.  The Intel(R) Core(tm) processors differ in specifications from the Intel(R) Xeon(tm) processors.  To switch between the Intel Core nodes and the Intel Xeon nodes, simply just call `qsub` with different node properties as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963f7ee-d184-4cfa-9b3d-45ac3dadc4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%qsub -l nodes=1:core:ppn=2\n",
    "cd $PBS_O_WORKDIR\n",
    "python ParallelCode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2477c3d-366c-42ef-98f0-a2595742dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97046ca7-2500-4d75-a127-c432316f8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%qsub -l nodes=1:xeon:ppn=2\n",
    "cd $PBS_O_WORKDIR\n",
    "python ParallelCode.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d583d4-0a3d-421a-9d39-fc8fdbd91d08",
   "metadata": {},
   "source": [
    "## Generating plots\n",
    "\n",
    "We would like to generate plots using the data we collected above.  Optimally, we'd generate data files that we could just simply import and plot, but for this time, it's okay to just create lists of data manually as this isn't really a class on data analysis.\n",
    "\n",
    "A nice video explaining plotting in Jupyter notebooks is available at: https://www.youtube.com/watch?v=Hr4yh1_4GlQ\n",
    "\n",
    "Practice by plotting the number of workers (or another variable, such as data draw size) against a response (such as wall time, cpu time, memory usage, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e641b4-3460-456b-bda3-bc6b93215795",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# all points saved as array\n",
    "x = np.array([2,4,6,8,10,12,14,16,18,20])\n",
    "y = np.array([26.37137222290039,12.796449184417725,8.501582622528076,6.437229156494141,5.096891403198242,4.514995336532593,5.060871839523315,4.5333778858184814,4.334452152252197,4.195279359817505])\n",
    "\n",
    "# line of best fit with 3 degrees\n",
    "model = np.poly1d(np.polyfit(x, y, 3))\n",
    "\n",
    "#create a scatterplot line for line of best fit\n",
    "polyline = np.linspace(2, 20, 50)\n",
    "\n",
    "# plot the line of best fit with red line\n",
    "plt.plot(polyline, model(polyline), '--', color='red')\n",
    "\n",
    "#add points to plot\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# values for the x axis\n",
    "plt.xticks([0,2,4,6,8,10,12,14,16,18,20])\n",
    "\n",
    "# values for the y axis\n",
    "plt.yticks([0,3,6,9,12,15,18,21,24,27,30])\n",
    "\n",
    "# title of graph\n",
    "plt.title(\"Number of workers vs. Time to complete (secs) with 10,000,000 points\")\n",
    "\n",
    "# labels for each axis\n",
    "plt.xlabel(\"Number of workers\", fontsize = 18)\n",
    "plt.ylabel(\"Time to complete\", fontsize = 16)\n",
    "\n",
    "print(\"Line of best fit equation:\\n \"+str(model)+\"\\n\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86774e4-a9e7-4a17-b5e9-631d4d72f97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d17fb8c5-00a3-4812-8309-8b8a14b9c8c6",
   "metadata": {},
   "source": [
    "## Presenting data/plots inline with Markdown text\n",
    "\n",
    "Now that you have your data and know how to plot your data, create Markdown and code cells below to answer the following questions in report format (incorporating the code cells to generate plots):\n",
    "\n",
    "1. What software application did you choose to attempt to parallelize or augment?\n",
    "2. How did you parallelize or augment your chosen software application?\n",
    "3. How did the throughput or latency of your software application change as you increased the number of resources (workers, CPUs, etc.)?\n",
    "4. Were there any differences between the Linux system performance measurement tools and your language-based measurement tools?  What may be the cause of that?\n",
    "5. What would you change if you were to attempt this project again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05b831-1103-40e5-802a-558e9f29a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown \n",
    "\n",
    "# Monte Carlo method for finding pi paralellization report\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I decided to chose to focus on parallelizing the Monte Carlo method for \n",
    "finding pi because I wanted to see how the speed of the program decreased or increased with an increase in workers and \n",
    "how much time is taken depending on the sample size. I ultimately found that the program is a lot faster when there are \n",
    "more workers that are operating, however, this speed does eventually plateau and regardless of many workers you have \n",
    "after time to complete doesn't change much.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I parallelized the software application by dividing the sample size given by the user\n",
    "into smaller sizes that each worker would be in charge of, the smaller size was calculated by dividing the sample size \n",
    "by the number of workers the user wanted. With the smaller sample size, each worker (or process as it was called in the program)\n",
    "is created using the multiprocess module, they are then in charge of using the definition of the Monte Carlo method to create\n",
    "random points, determine whether they are valid, and then save the vaid points in their respective array. After each of the workers\n",
    "complete their respective task, all the info is sent back to the main method to determine what the estimation of pi is. The\n",
    "main method then proceeds to creating printing the amount of time taken to complete the entire process and the estimation of pi\n",
    "in the given iteration.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As I stated in the beginning, the time taken to complete the task reduces with \n",
    "an increased number of workers, however, it does end up plateauing after reaching a certain amount of workers. Not only this, \n",
    "but as the number of workers increased the latency ended up reducing by a significant amount, this can be seen in the reduced \n",
    "amount of time to in the graph below (figure 2.1). On the contrary, if the amount of workers was constant, as the sample\n",
    "size increases, the latency begins to drastically increase and it eventually causes the program to never return a output\n",
    "due to the high amount of work that needs to completed. In the case of figure 2.1, we can see that after reaching 10 workers\n",
    "the amount of time needed to complete the program doesn't drop below 3 seconds. Based off this information we can assume that \n",
    "the program has reached a plateau in terms of how efficient it can be, and this ultimately varies becuase every user has\n",
    "a different cpu and operating system that affects the performance times. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There was a slight difference in the different measurement tools but the difference\n",
    "is small enough to be negligible. The difference in times between the measurement tools was around 0.0003 seconds of a difference.\n",
    "One possible explanation for this is because the python measurement tool needed to perform \n",
    "a couple more tasks in order to complete the same task as the linux system performance measurement tools. For the purpose\n",
    "of this program, I decided to use the 'time' module that is provided as a python library, the reason for this was because\n",
    "I found it easier to understand and it was able to give me the time that had passed in seconds.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; One thing I would for change is the presentation of the data collected. One way in \n",
    "which I would do this is by creating two tables, one in which the amount of workers increases with a fixed sample size\n",
    "(such as the graph provided below) and another which the sample size increases with a fixed amount of workers. This would \n",
    "demonstrate how paralellization and the amount of workers can not only decrease the amount of time needed to complete a \n",
    "program but it would also show how as a sample size increases the amount of time increases exponentially until the task \n",
    "would take too long to complete.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60423e-8a03-4570-a839-b785a4886e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Figure 2.1\")\n",
    "\n",
    "# all points saved as array\n",
    "x = np.array([2,4,6,8,10,12,14,16,18,20])\n",
    "y = np.array([26.37137222290039,12.796449184417725,8.501582622528076,6.437229156494141,5.096891403198242,4.514995336532593,5.060871839523315,4.5333778858184814,4.334452152252197,4.195279359817505])\n",
    "\n",
    "# line of best fit with 3 degrees\n",
    "model = np.poly1d(np.polyfit(x, y, 3))\n",
    "\n",
    "#create a scatterplot line for line of best fit\n",
    "polyline = np.linspace(2, 20, 50)\n",
    "\n",
    "# plot the line of best fit with red line\n",
    "plt.plot(polyline, model(polyline), '--', color='red')\n",
    "\n",
    "#add points to plot\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# values for the x axis\n",
    "plt.xticks([0,2,4,6,8,10,12,14,16,18,20])\n",
    "\n",
    "# values for the y axis\n",
    "plt.yticks([0,3,6,9,12,15,18,21,24,27,30])\n",
    "\n",
    "# title of graph\n",
    "plt.title(\"Number of workers vs. Time to complete (secs) with 10,000,000 points\")\n",
    "\n",
    "# labels for each axis\n",
    "plt.xlabel(\"Number of workers\", fontsize = 18)\n",
    "plt.ylabel(\"Time to complete\", fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
